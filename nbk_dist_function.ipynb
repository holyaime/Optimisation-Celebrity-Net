{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/holy/.cache/pypoetry/virtualenvs/celebrity-recognition-ai-pJrLk7n1-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from celebrity_recognition_ai.ml.data import get_train_and_validation_images_path\n",
    "from celebrity_recognition_ai.ml.data import CelebrityDataset\n",
    "\n",
    "from celebrity_recognition_ai.ml.models import CelebrityNet\n",
    "from celebrity_recognition_ai.ml.student_bo import StudentNetbo\n",
    "from celebrity_recognition_ai.ml.mobilenet_v2_100 import Mobilenet_100\n",
    "from celebrity_recognition_ai.ml import etudiant\n",
    "\n",
    "\n",
    "from celebrity_recognition_ai.ml.ModifiedCelebrityCosinus import ModifiedCelebrityCosinu\n",
    "from celebrity_recognition_ai.ml.modifiedStudentCosinus import ModifiedStudentNetboCosinu\n",
    "from celebrity_recognition_ai.ml import ModifiedCelebrityRegressor\n",
    "from celebrity_recognition_ai.ml import ModifiedEtudiantReg \n",
    "from celebrity_recognition_ai.ml import ModifiedStudentb0Regressor\n",
    "from celebrity_recognition_ai.ml import modifiedMobileRegressor\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import copy\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vider les caches CUDA\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"celebrity_recognition_ai/configs/celebrity-config.yaml\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    content = yaml.safe_load(file)\n",
    "    categories = content[\"transverse\"][\"categories\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(909, 229, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = \"../celebrity-recognition-ai/Data2\"\n",
    "#categorie= os.listdir(base_path)\n",
    "(trainset, valset) = get_train_and_validation_images_path(base_path,categories)\n",
    "len(trainset), len(valset),len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(878, 216)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainsetloader = CelebrityDataset(trainset, categories)\n",
    "valsetloader = CelebrityDataset(valset,categories,train=False)\n",
    "len_trainset = len(trainsetloader)\n",
    "len_valset = len(valsetloader)\n",
    "len_trainset ,len_valset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        trainsetloader, batch_size= 16, shuffle=True, num_workers=8\n",
    "    )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        valsetloader, batch_size= 16, shuffle=False, num_workers=8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4590/3269549141.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cel_teach.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CelebrityNet(\n",
       "  (backbone): EfficientNet(\n",
       "    (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNormAct2d(\n",
       "      48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(336, 336, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=336, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1632, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2688, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(2688, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(112, 2688, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNormAct2d(\n",
       "      1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (classifier): Linear(in_features=1792, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path ='/home/holy/Documents/memoire/celebrity-recognition-ai/celebrity_recognition_ai/app/trained-models/celebritynet.pth'\n",
    "cel_teach = CelebrityNet()\n",
    "cel_teach.load_state_dict(torch.load(model_path))\n",
    "cel_teach.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cel_etud1 = StudentNetbo()\n",
    "# cel_etud1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cel_etud1 =etudiant2.StudentEfficientNetB4()\n",
    "# cel_etud1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cel_etud1 =  ModifiedStudentRegEfficientNetB4()\n",
    "# cel_etud1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cel_etud1 = EfficientNetB0()\n",
    "# cel_etud1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mobilenet_100(\n",
       "  (backbone): EfficientNet(\n",
       "    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNormAct2d(\n",
       "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): ReLU6(inplace=True)\n",
       "    )\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU6(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNormAct2d(\n",
       "      1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): ReLU6(inplace=True)\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=1280, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cel_etud1 = Mobilenet_100()\n",
    "cel_etud1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de paramtres du modle enseignant: 17,559,374\n",
      "Nombre de paramtres du modle tudiant: 2,231,558\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Utilisation\n",
    "teacher_params = count_parameters(cel_teach)\n",
    "student_params = count_parameters(cel_etud1)\n",
    "\n",
    "print(f\"Nombre de paramtres du modle enseignant: {teacher_params:,}\")\n",
    "print(f\"Nombre de paramtres du modle tudiant: {student_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training fonction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train_knowledge_distillation(teacher, student, train_loader, val_loader, epochs, learning_rate, T, soft_target_loss_weight, ce_loss_weight, device, patience):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(student.parameters(), lr=learning_rate)  # Utilisation d'Adam\n",
    "    teacher.eval()\n",
    "    student.train()\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        student.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            teacher_logits = teacher(inputs)\n",
    "            student_logits = student(inputs)\n",
    "\n",
    "            soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
    "            soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
    "\n",
    "            soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (T**2)\n",
    "            label_loss = ce_loss(student_logits, labels)\n",
    "\n",
    "            loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Average training loss for this epoch\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss = 0.0\n",
    "        student.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                teacher_logits = teacher(inputs)\n",
    "                student_logits = student(inputs)\n",
    "\n",
    "                soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
    "                soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
    "\n",
    "                soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (T**2)\n",
    "                label_loss = ce_loss(student_logits, labels)\n",
    "\n",
    "                loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        # Log training and validation losses to TensorBoard\n",
    "        writer.add_scalar('Training Loss', train_loss, epoch)\n",
    "        writer.add_scalar('Validation Loss', val_loss, epoch)\n",
    "        writer.flush()  # Ensure data is written to disk\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss}, Val Loss: {val_loss}\")\n",
    "\n",
    "        # Early Stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(student.state_dict(), \"mobile__best0.pth\")  # Sauvegarde avec un nom plus gnrique\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    writer.close()\n",
    "    print(f\"Model saved with best validation loss of {best_val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 2.6476430979642003, Val Loss: 2.4400667463030135\n",
      "Epoch 2/200, Loss: 2.3347442930394955, Val Loss: 2.258947031838553\n",
      "Epoch 3/200, Loss: 2.2402209108526057, Val Loss: 2.09217323575701\n",
      "Epoch 4/200, Loss: 2.106643171743913, Val Loss: 2.015709783349718\n",
      "Epoch 5/200, Loss: 2.110959193923257, Val Loss: 2.028362444468907\n",
      "Epoch 6/200, Loss: 2.090108706734397, Val Loss: 2.014676775251116\n",
      "Epoch 7/200, Loss: 2.1274348519065165, Val Loss: 2.1889026165008545\n",
      "Epoch 8/200, Loss: 2.0953677979382603, Val Loss: 2.071103879383632\n",
      "Epoch 9/200, Loss: 2.1164385882290926, Val Loss: 2.129349912915911\n",
      "Epoch 10/200, Loss: 2.1127379460768267, Val Loss: 2.088277110031673\n",
      "Epoch 11/200, Loss: 2.1081356807188554, Val Loss: 2.146309060709817\n",
      "Epoch 12/200, Loss: 2.098303107781844, Val Loss: 2.0895494648388455\n",
      "Epoch 13/200, Loss: 2.093988132476807, Val Loss: 2.0819385732923235\n",
      "Epoch 14/200, Loss: 2.0963321339000354, Val Loss: 2.103567804609026\n",
      "Epoch 15/200, Loss: 2.0992878437042237, Val Loss: 2.0948173148291453\n",
      "Epoch 16/200, Loss: 2.064355557615107, Val Loss: 2.134340865271432\n",
      "Epoch 17/200, Loss: 2.088627301562916, Val Loss: 2.1275247079985484\n",
      "Epoch 18/200, Loss: 2.1025345823981545, Val Loss: 2.105608114174434\n",
      "Epoch 19/200, Loss: 2.086914738741788, Val Loss: 2.104424774646759\n",
      "Epoch 20/200, Loss: 2.1007273847406562, Val Loss: 2.130405698503767\n",
      "Epoch 21/200, Loss: 2.07880155173215, Val Loss: 2.3389909693173\n",
      "Epoch 22/200, Loss: 2.0664602388035167, Val Loss: 2.7421145098549977\n",
      "Epoch 23/200, Loss: 2.0694877646186134, Val Loss: 2.0726485507828847\n",
      "Epoch 24/200, Loss: 2.068705769018693, Val Loss: 2.110732819352831\n",
      "Epoch 25/200, Loss: 2.0413162448189475, Val Loss: 2.0186886531966075\n",
      "Epoch 26/200, Loss: 2.041685037179427, Val Loss: 1.9744618364742823\n",
      "Epoch 27/200, Loss: 2.0413398309187456, Val Loss: 2.060138157435826\n",
      "Epoch 28/200, Loss: 2.029630853913047, Val Loss: 2.012444402490343\n",
      "Epoch 29/200, Loss: 2.0000493223016913, Val Loss: 1.92883334841047\n",
      "Epoch 30/200, Loss: 1.997021659937772, Val Loss: 2.1128512110028947\n",
      "Epoch 31/200, Loss: 2.002726754275235, Val Loss: 2.001033842563629\n",
      "Epoch 32/200, Loss: 1.986839957670732, Val Loss: 1.9492831485612052\n",
      "Epoch 33/200, Loss: 2.011242372339422, Val Loss: 1.989092230796814\n",
      "Epoch 34/200, Loss: 2.005123268474232, Val Loss: 2.055413373879024\n",
      "Epoch 35/200, Loss: 2.0033632950349287, Val Loss: 1.9824713809149606\n",
      "Epoch 36/200, Loss: 2.018635719472712, Val Loss: 1.945140608719417\n",
      "Epoch 37/200, Loss: 1.981459951400757, Val Loss: 1.917473486491612\n",
      "Epoch 38/200, Loss: 1.9686445366252552, Val Loss: 1.8844690663473946\n",
      "Epoch 39/200, Loss: 1.933959150314331, Val Loss: 1.8155315603528703\n",
      "Epoch 40/200, Loss: 1.956090755896135, Val Loss: 1.9343934740339006\n",
      "Epoch 41/200, Loss: 1.9434218861839987, Val Loss: 1.8693676420620509\n",
      "Epoch 42/200, Loss: 1.9246358546343716, Val Loss: 1.9291768755231584\n",
      "Epoch 43/200, Loss: 1.9738432970913973, Val Loss: 2.0021713290895735\n",
      "Epoch 44/200, Loss: 1.9500299518758601, Val Loss: 1.8839878695351737\n",
      "Epoch 45/200, Loss: 1.9433154994791204, Val Loss: 1.8005703687667847\n",
      "Epoch 46/200, Loss: 1.939498420195146, Val Loss: 1.8602685332298279\n",
      "Epoch 47/200, Loss: 1.943930790641091, Val Loss: 1.8420877201216561\n",
      "Epoch 48/200, Loss: 1.9022767543792725, Val Loss: 1.9971836124147688\n",
      "Epoch 49/200, Loss: 1.919352609461004, Val Loss: 2.159998212541853\n",
      "Epoch 50/200, Loss: 1.966709659316323, Val Loss: 1.9009015730449133\n",
      "Epoch 51/200, Loss: 1.905612412366, Val Loss: 1.857696226664952\n",
      "Epoch 52/200, Loss: 1.946913446079601, Val Loss: 1.9379620466913496\n",
      "Epoch 53/200, Loss: 1.9296964927153153, Val Loss: 1.8628586871283395\n",
      "Epoch 54/200, Loss: 1.9479314890774813, Val Loss: 1.879728410925184\n",
      "Epoch 55/200, Loss: 1.9240154938264327, Val Loss: 1.8853317924908228\n",
      "Epoch 56/200, Loss: 1.9050034067847512, Val Loss: 1.915621165718351\n",
      "Epoch 57/200, Loss: 1.9046203309839422, Val Loss: 1.9853585362434387\n",
      "Epoch 58/200, Loss: 1.928614354133606, Val Loss: 1.8735128045082092\n",
      "Epoch 59/200, Loss: 1.892910278927196, Val Loss: 1.8041109442710876\n",
      "Epoch 60/200, Loss: 1.8608310244300148, Val Loss: 1.8939650058746338\n",
      "Epoch 61/200, Loss: 1.9626198768615724, Val Loss: 2.0021489432879855\n",
      "Epoch 62/200, Loss: 1.899759379300204, Val Loss: 1.8269967181341988\n",
      "Epoch 63/200, Loss: 1.9340841618451206, Val Loss: 1.8450765780040197\n",
      "Epoch 64/200, Loss: 1.8767345125024968, Val Loss: 1.8953072343553816\n",
      "Epoch 65/200, Loss: 1.8979290810498324, Val Loss: 1.7849779043878828\n",
      "Epoch 66/200, Loss: 1.9152127460999921, Val Loss: 1.8811087352888924\n",
      "Epoch 67/200, Loss: 1.9320658315311778, Val Loss: 1.8625416925975256\n",
      "Epoch 68/200, Loss: 1.9177927147258411, Val Loss: 2.4508024539266313\n",
      "Epoch 69/200, Loss: 1.9455610990524292, Val Loss: 1.8438106094087874\n",
      "Epoch 70/200, Loss: 1.8649421323429454, Val Loss: 1.7608272305556707\n",
      "Epoch 71/200, Loss: 1.8560200929641724, Val Loss: 1.8343812738146101\n",
      "Epoch 72/200, Loss: 1.8595265691930598, Val Loss: 1.810425307069506\n",
      "Epoch 73/200, Loss: 1.9050430536270142, Val Loss: 1.787268306527819\n",
      "Epoch 74/200, Loss: 1.9406111305410212, Val Loss: 1.924800992012024\n",
      "Epoch 75/200, Loss: 1.9339003476229581, Val Loss: 1.951430184500558\n",
      "Epoch 76/200, Loss: 1.9283729683269153, Val Loss: 1.9309869153159005\n",
      "Epoch 77/200, Loss: 1.9229991566051137, Val Loss: 1.8092878546033586\n",
      "Epoch 78/200, Loss: 1.8927362853830512, Val Loss: 1.7501971125602722\n",
      "Epoch 79/200, Loss: 1.8927039861679078, Val Loss: 1.779811109815325\n",
      "Epoch 80/200, Loss: 1.9178390979766846, Val Loss: 1.7447616798537118\n",
      "Epoch 81/200, Loss: 1.867794791134921, Val Loss: 1.8080326063292367\n",
      "Epoch 82/200, Loss: 1.8869989091699773, Val Loss: 1.8080708725111825\n",
      "Epoch 83/200, Loss: 1.8416043563322588, Val Loss: 1.732302827494485\n",
      "Epoch 84/200, Loss: 1.8782212950966575, Val Loss: 1.814213250364576\n",
      "Epoch 85/200, Loss: 1.8872746554287998, Val Loss: 1.859113642147609\n",
      "Epoch 86/200, Loss: 1.8979746124961159, Val Loss: 1.8849398919514246\n",
      "Epoch 87/200, Loss: 1.880116092075001, Val Loss: 1.7944560306412833\n",
      "Epoch 88/200, Loss: 1.8666607943448152, Val Loss: 1.8380666630608695\n",
      "Epoch 89/200, Loss: 1.8712733095342462, Val Loss: 1.9553631799561637\n",
      "Epoch 90/200, Loss: 1.9390148834748702, Val Loss: 1.9527090617588587\n",
      "Epoch 91/200, Loss: 1.852043674208901, Val Loss: 1.803119352885655\n",
      "Epoch 92/200, Loss: 1.90359393900091, Val Loss: 1.7433783326830183\n",
      "Epoch 93/200, Loss: 1.838322522423484, Val Loss: 1.805010003702981\n",
      "Epoch 94/200, Loss: 1.839601341160861, Val Loss: 1.882892600127629\n",
      "Epoch 95/200, Loss: 1.8426658673719927, Val Loss: 1.929194722856794\n",
      "Epoch 96/200, Loss: 1.884717082977295, Val Loss: 1.7771668008395605\n",
      "Epoch 97/200, Loss: 1.8734609148719095, Val Loss: 1.9534284472465515\n",
      "Epoch 98/200, Loss: 1.8869980096817016, Val Loss: 1.8256844197000777\n",
      "Epoch 99/200, Loss: 1.8768957289782437, Val Loss: 1.9069705520357405\n",
      "Epoch 100/200, Loss: 1.9099079717289318, Val Loss: 1.8291273713111877\n",
      "Epoch 101/200, Loss: 1.8546808004379272, Val Loss: 1.749189819608416\n",
      "Epoch 102/200, Loss: 1.8798330653797497, Val Loss: 1.7731475404330663\n",
      "Epoch 103/200, Loss: 1.841184080730785, Val Loss: 1.753442304474967\n",
      "Epoch 104/200, Loss: 1.8461133501746438, Val Loss: 1.8488203372274126\n",
      "Epoch 105/200, Loss: 1.813674061948603, Val Loss: 1.7048558379922594\n",
      "Epoch 106/200, Loss: 1.86457134810361, Val Loss: 1.8681512815611703\n",
      "Epoch 107/200, Loss: 1.7674907706000589, Val Loss: 1.8661332896777563\n",
      "Epoch 108/200, Loss: 1.847869756005027, Val Loss: 1.7640965666089738\n",
      "Epoch 109/200, Loss: 1.8708859530362216, Val Loss: 1.746288733822959\n",
      "Epoch 110/200, Loss: 1.8251559387553822, Val Loss: 1.7245841537203108\n",
      "Epoch 111/200, Loss: 1.8105156421661377, Val Loss: 1.68723441021783\n",
      "Epoch 112/200, Loss: 1.8283432527021928, Val Loss: 1.7750198500497\n",
      "Epoch 113/200, Loss: 1.8050349300557917, Val Loss: 1.6670835529054915\n",
      "Epoch 114/200, Loss: 1.834587619521401, Val Loss: 1.8966232453073775\n",
      "Epoch 115/200, Loss: 1.8141438874331388, Val Loss: 1.7313037301812852\n",
      "Epoch 116/200, Loss: 1.838611912727356, Val Loss: 1.6954568028450012\n",
      "Epoch 117/200, Loss: 1.7843130393461748, Val Loss: 1.6915402838162013\n",
      "Epoch 118/200, Loss: 1.746458718993447, Val Loss: 1.622358066695077\n",
      "Epoch 119/200, Loss: 1.8671733834526756, Val Loss: 1.7308262842042106\n",
      "Epoch 120/200, Loss: 1.8166385997425427, Val Loss: 1.7134341086660112\n",
      "Epoch 121/200, Loss: 1.8588635336269033, Val Loss: 1.6954402327537537\n",
      "Epoch 122/200, Loss: 1.8108103036880494, Val Loss: 1.699809695993151\n",
      "Epoch 123/200, Loss: 1.769481814991344, Val Loss: 1.778011875493186\n",
      "Epoch 124/200, Loss: 1.7676796024495904, Val Loss: 1.782893989767347\n",
      "Epoch 125/200, Loss: 1.7348756183277476, Val Loss: 1.6733015094484602\n",
      "Epoch 126/200, Loss: 1.7823800347068093, Val Loss: 1.6789637207984924\n",
      "Epoch 127/200, Loss: 1.807274038141424, Val Loss: 1.6741703578404017\n",
      "Epoch 128/200, Loss: 1.7724559740586714, Val Loss: 1.695300613130842\n",
      "Epoch 129/200, Loss: 1.7538304350592873, Val Loss: 1.6038297840527125\n",
      "Epoch 130/200, Loss: 1.7627196788787842, Val Loss: 1.6785121049199785\n",
      "Epoch 131/200, Loss: 1.7952434821562333, Val Loss: 1.6156481334141322\n",
      "Epoch 132/200, Loss: 1.7427616292780095, Val Loss: 1.76691620690482\n",
      "Epoch 133/200, Loss: 1.7425715099681507, Val Loss: 1.8705937904970986\n",
      "Epoch 134/200, Loss: 1.7533205639232288, Val Loss: 1.6329057727541243\n",
      "Epoch 135/200, Loss: 1.7496022896333174, Val Loss: 1.7275077274867467\n",
      "Epoch 136/200, Loss: 1.7839549042961813, Val Loss: 1.6841287016868591\n",
      "Epoch 137/200, Loss: 1.7210292534394698, Val Loss: 1.787415623664856\n",
      "Epoch 138/200, Loss: 1.7387756889516657, Val Loss: 1.6314280118261064\n",
      "Epoch 139/200, Loss: 1.7058823910626497, Val Loss: 1.6432823709079198\n",
      "Epoch 140/200, Loss: 1.7170549349351363, Val Loss: 1.6462551610810416\n",
      "Epoch 141/200, Loss: 1.7375737276944248, Val Loss: 1.7217423830713545\n",
      "Epoch 142/200, Loss: 1.6952309153296732, Val Loss: 1.6882124074867793\n",
      "Epoch 143/200, Loss: 1.7453871163454924, Val Loss: 1.6784982425825936\n",
      "Epoch 144/200, Loss: 1.6904093178835782, Val Loss: 1.6979474936212813\n",
      "Epoch 145/200, Loss: 1.7382049777291038, Val Loss: 1.7468582221439906\n",
      "Epoch 146/200, Loss: 1.7158996842124246, Val Loss: 1.7783534611974443\n",
      "Epoch 147/200, Loss: 1.7078557014465332, Val Loss: 1.7098433545657568\n",
      "Epoch 148/200, Loss: 1.6815395897085017, Val Loss: 1.9283387064933777\n",
      "Epoch 149/200, Loss: 1.6914833263917404, Val Loss: 1.7218642575400216\n",
      "Epoch 150/200, Loss: 1.7155827565626665, Val Loss: 1.719507098197937\n",
      "Epoch 151/200, Loss: 1.728608244115656, Val Loss: 1.7304319994790214\n",
      "Epoch 152/200, Loss: 1.8064267895438455, Val Loss: 1.7617979390280587\n",
      "Epoch 153/200, Loss: 1.6759045991030606, Val Loss: 1.6836908459663391\n",
      "Epoch 154/200, Loss: 1.6594022967598654, Val Loss: 1.5542176706450326\n",
      "Epoch 155/200, Loss: 1.7580925681374289, Val Loss: 1.8068581138338362\n",
      "Epoch 156/200, Loss: 1.661251094124534, Val Loss: 1.6425117765154158\n",
      "Epoch 157/200, Loss: 1.6945353789763018, Val Loss: 1.6142383345535822\n",
      "Epoch 158/200, Loss: 1.696552434834567, Val Loss: 1.6523264391081673\n",
      "Epoch 159/200, Loss: 1.6958249959078702, Val Loss: 1.6893711856433324\n",
      "Epoch 160/200, Loss: 1.7324633359909059, Val Loss: 1.6951993448393685\n",
      "Epoch 161/200, Loss: 1.6648418881676414, Val Loss: 1.536383616072791\n",
      "Epoch 162/200, Loss: 1.6732375448400325, Val Loss: 1.5406550083841597\n",
      "Epoch 163/200, Loss: 1.6656526977365667, Val Loss: 1.682863976274218\n",
      "Epoch 164/200, Loss: 1.6464921474456786, Val Loss: 1.738864289862769\n",
      "Epoch 165/200, Loss: 1.6350545558062466, Val Loss: 1.6321700385638647\n",
      "Epoch 166/200, Loss: 1.6942713130604137, Val Loss: 1.6971820422581263\n",
      "Epoch 167/200, Loss: 1.718899713863026, Val Loss: 1.5689650944301061\n",
      "Epoch 168/200, Loss: 1.6992082249034535, Val Loss: 1.6678326640810286\n",
      "Epoch 169/200, Loss: 1.664222981713035, Val Loss: 1.6487132140568324\n",
      "Epoch 170/200, Loss: 1.6798096353357488, Val Loss: 1.7507711734090532\n",
      "Epoch 171/200, Loss: 1.6441198609092018, Val Loss: 1.6664759346417017\n",
      "Epoch 172/200, Loss: 1.702958093989979, Val Loss: 1.573928781918117\n",
      "Epoch 173/200, Loss: 1.6571666847575794, Val Loss: 1.5546060417379652\n",
      "Epoch 174/200, Loss: 1.6785015691410412, Val Loss: 1.6233703664370946\n",
      "Epoch 175/200, Loss: 1.7010143345052546, Val Loss: 1.520275660923549\n",
      "Epoch 176/200, Loss: 1.6222128499637951, Val Loss: 1.5718106116567339\n",
      "Epoch 177/200, Loss: 1.593768713691018, Val Loss: 1.6023630925587244\n",
      "Epoch 178/200, Loss: 1.6141974275762385, Val Loss: 1.6465593533856528\n",
      "Epoch 179/200, Loss: 1.6463254343379627, Val Loss: 1.573695753301893\n",
      "Epoch 180/200, Loss: 1.672775615345348, Val Loss: 1.6469501427241735\n",
      "Epoch 181/200, Loss: 1.645446818525141, Val Loss: 1.7128814033099584\n",
      "Epoch 182/200, Loss: 1.6911304040388628, Val Loss: 1.654452153614589\n",
      "Epoch 183/200, Loss: 1.613558402928439, Val Loss: 1.5862227635724204\n",
      "Epoch 184/200, Loss: 1.598071254383434, Val Loss: 1.768709421157837\n",
      "Epoch 185/200, Loss: 1.6639437068592418, Val Loss: 1.6330677824360984\n",
      "Epoch 186/200, Loss: 1.6018406694585627, Val Loss: 1.6877466525350298\n",
      "Epoch 187/200, Loss: 1.6356649290431629, Val Loss: 1.5405833891459875\n",
      "Epoch 188/200, Loss: 1.5919101411646062, Val Loss: 1.7071065306663513\n",
      "Epoch 189/200, Loss: 1.592501746524464, Val Loss: 1.6298458320753915\n",
      "Epoch 190/200, Loss: 1.5290448427200318, Val Loss: 1.5007511121886117\n",
      "Epoch 191/200, Loss: 1.5497052994641392, Val Loss: 1.5049256810120173\n",
      "Epoch 192/200, Loss: 1.5825564709576694, Val Loss: 1.4566160440444946\n",
      "Epoch 193/200, Loss: 1.5888917684555053, Val Loss: 1.5130280085972376\n",
      "Epoch 194/200, Loss: 1.5913199424743651, Val Loss: 1.4656758393560136\n",
      "Epoch 195/200, Loss: 1.516611344164068, Val Loss: 1.4921059353010995\n",
      "Epoch 196/200, Loss: 1.5353406559337268, Val Loss: 1.4597809314727783\n",
      "Epoch 197/200, Loss: 1.5402883746407248, Val Loss: 1.5545907957213265\n",
      "Epoch 198/200, Loss: 1.5578934149308639, Val Loss: 1.5464094281196594\n",
      "Epoch 199/200, Loss: 1.582782431082292, Val Loss: 1.5508970192500524\n",
      "Epoch 200/200, Loss: 1.494661977074363, Val Loss: 1.5058524821485793\n",
      "Model saved with best validation loss of 1.4566160440444946\n"
     ]
    }
   ],
   "source": [
    "stud = train_knowledge_distillation(teacher=cel_teach, student=cel_etud1, train_loader= train_loader,val_loader=val_loader, epochs=200, learning_rate=0.01, T=1, soft_target_loss_weight=0.6, ce_loss_weight=0.75, device=device, patience=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction d'entrainement des modles avec regresseur intermediaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path ='../celebrity_recognition_ai/app/trained-models/celebritynet.pth'\n",
    "cel_teach = CelebrityNet()\n",
    "cel_teach.load_state_dict(torch.load(model_path))\n",
    "cel_teach=cel_teach.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the modified teacher template\n",
    "modi_cel_teach = ModifiedCelebrityRegressor().to(device)\n",
    "modi_cel_teach.load_state_dict(cel_teach.state_dict())\n",
    "modi_cel_teach\n",
    "\n",
    "# Loading the modified student model\n",
    "modi_cel_reg = modifiedMobileRegressor().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for models with intermediate rectifier\n",
    "def train_mse_loss(teacher, student, train_loader, epochs, learning_rate, feature_map_weight, ce_loss_weight, device):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(student.parameters(), lr=learning_rate)\n",
    "\n",
    "    teacher.to(device)\n",
    "    student.to(device)\n",
    "    teacher.eval()  \n",
    "    student.train() \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.ttorch.cuda.empty_cache()o(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                _, teacher_feature_map = teacher(inputs)\n",
    "\n",
    "\n",
    "            # Forward pass with the student model\n",
    "            student_logits, regressor_feature_map = student(inputs)\n",
    "\n",
    "            # Calculate the loss\n",
    "            hidden_rep_loss = mse_loss(regressor_feature_map, teacher_feature_map)\n",
    "\n",
    "            # Calculate the true label loss\n",
    "            label_loss = ce_loss(student_logits, labels)\n",
    "\n",
    "            # Weighted sum of the two losses\n",
    "            loss = feature_map_weight * hidden_rep_loss + ce_loss_weight * label_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "       # Enregistrer le modle tudiant entran\n",
    "    path = \"../celebrity-recognition-ai/mobil_reg001.pth\"\n",
    "    torch.save(student.state_dict(),path)\n",
    "    print(f\"Model saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse_loss(teacher=modi_cel_teach, student=modi_cel_reg , train_loader=train_loader, epochs=330, learning_rate=0.01, feature_map_weight=0.6, ce_loss_weight=0.75, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOSS COSINUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modi_cel_etu = ModifiedStudentNetboCosinu().to(device)\n",
    "modi_cel_etu.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modi_cel_tea = ModifiedCelebrityCosinu().to(device)\n",
    "modi_cel_tea.load_state_dict(cel_teach.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drive function for models with cosine loss\n",
    "\n",
    "def train_cosine_loss(teacher, student, train_loader, epochs, learning_rate, hidden_rep_loss_weight, ce_loss_weight, device):\n",
    "    ce_loss = torch.nn.CrossEntropyLoss()\n",
    "    cosine_loss = torch.nn.CosineEmbeddingLoss()\n",
    "    optimizer = torch.optim.SGD(student.parameters(), lr=learning_rate)\n",
    "\n",
    "    teacher.to(device)\n",
    "    student.to(device)\n",
    "    teacher.eval()  \n",
    "    student.train() \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass with the teacher model and keep only the hidden representation\n",
    "            with torch.no_grad():\n",
    "                _, teacher_hidden_representation = teacher(inputs)\n",
    "\n",
    "            # Forward pass with the student model\n",
    "            student_logits, student_hidden_representation = student(inputs)\n",
    "\n",
    "            # Calculate the cosine loss. Target is a vector of ones. From the loss formula above we can see that is the case where loss minimization leads to cosine similarity increase.\n",
    "            hidden_rep_loss = cosine_loss(student_hidden_representation, teacher_hidden_representation, target=torch.ones(inputs.size(0)).to(device))\n",
    "\n",
    "            # Calculate the true label loss\n",
    "            label_loss = ce_loss(student_logits, labels)\n",
    "\n",
    "            # Weighted sum of the two losses\n",
    "            loss = hidden_rep_loss_weight * hidden_rep_loss + ce_loss_weight * label_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "            # Enregistrer le modle tudiant entran\n",
    "    path = \"../celebrity-recognition-ai/model_cosLoss_01.pth\"\n",
    "    torch.save(student.state_dict(),path)\n",
    "    print(f\"Model saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cosine_loss(modi_cel_tea, modi_cel_etu, train_loader, epochs = 330, learning_rate=0.01, hidden_rep_loss_weight=0.6, ce_loss_weight=0.75,device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celebrity-recognition-ai-qx_VLdYi-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
